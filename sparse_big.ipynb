{
 "metadata": {
  "name": "",
  "signature": "sha256:aabedccead98462db2a8853cc7551ea459be08d55918a8faa8f138c7b1cba2f9"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from time import time\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "import os\n",
      "import Image as im\n",
      "import datetime as dt\n",
      "import pywt\n",
      "from sklearn.decomposition import MiniBatchDictionaryLearning, dict_learning_online\n",
      "from sklearn.feature_extraction.image import extract_patches_2d \n",
      "from sklearn.decomposition import fastica\n",
      "\n",
      "# Images in file\n",
      "basedir = 'data/all_512/'\n",
      "flist = os.listdir(basedir)\n",
      "flist = sorted(flist)\n",
      "num_images = len(flist)\n",
      "\n",
      "def masked_to_image(masked, sun_mask, image_size):\n",
      "    sun_image = np.zeros([image_size**2])\n",
      "    sun_image[sun_mask==1] = masked\n",
      "    sun_image = sun_image.reshape([image_size, image_size])\n",
      "    return sun_image\n",
      "\n",
      "def masked_to_image(masked, sun_mask, image_size):\n",
      "    sun_image = np.zeros([image_size**2])\n",
      "    sun_image[sun_mask==1] = masked\n",
      "    sun_image = sun_image.reshape([image_size, image_size])\n",
      "    return sun_image\n",
      "\n",
      "# Create mask array to select only within solar disk\n",
      "def make_sun_mask(centre, radius, image_size):\n",
      "    sun_mask = np.zeros([image_size,image_size], dtype=np.uint8)\n",
      "    for i in range(image_size):\n",
      "        for j in range(image_size):\n",
      "            dist = np.sqrt((centre[0] - i)**2 + (centre[1] - j)**2)\n",
      "            if dist<= radius:\n",
      "                sun_mask[i,j] = 1\n",
      "    return sun_mask\n",
      "# Make sun mask\n",
      "# Hi-res images\n",
      "# image_size = 512\n",
      "# centre = (255,255)\n",
      "# radius = 472/2\n",
      "image_size = 512\n",
      "centre = (127.5*2,127.5*2)\n",
      "radius = 234\n",
      "\n",
      "# Low-res images\n",
      "# image_size = 256\n",
      "# centre = (127.5,127.5)\n",
      "# radius = 234/2.0\n",
      "\n",
      "sun_mask = make_sun_mask(centre, radius, image_size)\n",
      "# data = extract_patches_2d(sun_mask, patch_size)\n",
      "# sun_mask_patches = np.sum(np.sum(abs(data),axis=2),axis=1)\n",
      "# Flatten array\n",
      "# sun_mask = np.ravel(sun_mask)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Initialise arrays\n",
      "years = np.zeros(num_images, dtype=np.uint16)\n",
      "months = np.zeros(num_images, dtype=np.uint8)\n",
      "days = np.zeros(num_images, dtype=np.uint8)\n",
      "hours = np.zeros(num_images, dtype=np.uint8)\n",
      "minutes = np.zeros(num_images, dtype=np.uint8)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "patch_size = 32\n",
      "non_zeros = 0\n",
      "first_run = 0\n",
      "image_slice = np.zeros([num_images,patch_size, patch_size], dtype=np.uint8) \n",
      "ij_zero_list = []\n",
      "for i in range(0,image_size,patch_size/2):\n",
      "    for j in range(0,image_size,patch_size/2):\n",
      "        count = 0\n",
      "        for image_file in flist: \n",
      "            if first_run == 1:\n",
      "                years[count] = image_file[0:4]\n",
      "                months[count] = image_file[4:6]\n",
      "                days[count] = image_file[6:8]\n",
      "                hours[count] = image_file[9:11]\n",
      "                minutes[count] = image_file[11:13]\n",
      "\n",
      "            cur_file = basedir + image_file  \n",
      "            # Read image, convert to greyscale, convert to np array\n",
      "            cur_image = np.asarray(im.open(cur_file).convert('L'))\n",
      "            cur_image = cur_image*sun_mask\n",
      "            image_slice[count,:,:] = cur_image[i:i+patch_size, j:j+patch_size]\n",
      "            count +=1\n",
      "            \n",
      "        first_run =0\n",
      "        if np.sum(image_slice) != 0:\n",
      "            non_zeros +=1\n",
      "        else:\n",
      "            ij_zero_list.append((i,j))\n",
      "        print i,j\n",
      "\n",
      "# Number of dict components\n",
      "num_comp = 1\n",
      "coded_images = np.zeros([num_images,non_zeros*num_comp], dtype=np.float32)\n",
      "\n",
      "print 'Should compress to ' + str(num_images) + ' by ' + str(non_zeros*num_comp)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "coded_count = 0\n",
      "for i in range(0,image_size,patch_size/2):\n",
      "    for j in range(0,image_size,patch_size/2):\n",
      "        if (i,j) not in ij_zero_list:\n",
      "            count = 0\n",
      "            for image_file in flist:\n",
      "                cur_file = basedir + image_file  \n",
      "                # Read image, convert to greyscale, convert to np array\n",
      "                cur_image = np.asarray(im.open(cur_file).convert('L'))\n",
      "                cur_image = cur_image*sun_mask\n",
      "                image_slice[count,:,:] = cur_image[i:i+patch_size, j:j+patch_size]\n",
      "                count +=1\n",
      " \n",
      "        patch_slice = image_slice\n",
      "        patch_slice = patch_slice.reshape(patch_slice.shape[0],-1)\n",
      "        patch_slice -= np.mean(patch_slice, axis=0)\n",
      "        patch_slice /= np.std(patch_slice, axis=0)\n",
      "\n",
      "        coded_images[:,coded_count*num_comp:(coded_count+1)*(num_comp)], _ = \\\n",
      "            dict_learning_online(patch_slice, n_components=num_comp)\n",
      "\n",
      "        coded_count += 1\n",
      "        print str(coded_count) + ' of ' + str(non_zeros)\n",
      "print 'Done'\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "SyntaxError",
       "evalue": "invalid syntax (<ipython-input-4-0748d36304a7>, line 12)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-0748d36304a7>\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    image_slice[count,:,:] = cur_image[i:i+patch_size, j:j+patch_size]]\u001b[0m\n\u001b[0m                                                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#####################################################################################\n",
      "# Import lasco CME catalogue - \n",
      "# Date\n",
      "# Time\n",
      "# Central_PA : Central size [deg] \n",
      "# Width : Angular width [deg]\n",
      "# L_speed : linear speed\n",
      "# 2nd_o_speed : 2nd order speed fit\n",
      "# 2nd_o_speed_20R : 2nd order speed fit @ 20R\n",
      "# Accel : Acceleration\n",
      "# Mass :\n",
      "# KE : Kinetic energy\n",
      "# MPA : Measurement position angle\n",
      "df_cmes = pd.read_csv(\"cme_catalogue.md\",delim_whitespace=True,error_bad_lines =False, warn_bad_lines=False )\n",
      "df_cmes.drop(['Comment1','Comment2', 'Comment3'], axis=1, inplace=True)\n",
      "df_cmes[['year','month','day']] = df_cmes.Date.str.extract('(\\d\\d\\d\\d)/(\\d\\d)/(\\d\\d)')\n",
      "df_cmes[['hour','minute']] = df_cmes.Time.str.extract('(\\d\\d):(\\d\\d)')\n",
      "\n",
      "df_cmes.drop(['Date','Time','KE','Mass','MPA'],axis=1, inplace=True)    \n",
      "df_cmes['CME'] = 1\n",
      "df_cmes['halo'] = df_cmes.Central_PA\n",
      "df_cmes.ix[df_cmes.halo!='Halo', 'halo'] = 0\n",
      "df_cmes.ix[df_cmes.halo=='Halo', 'halo'] = 1\n",
      "df_cmes.ix[df_cmes.Central_PA=='Halo', 'Central_PA'] = 360\n",
      "# Make the features integer\n",
      "for feature in df_cmes.columns:\n",
      "    df_cmes[feature] = df_cmes[feature].astype(int)\n",
      "# Sort all on year -> month->day\n",
      "df_cmes = df_cmes.sort(columns=['year','month','day'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Make datetime object in a new columns\n",
      "df_cmes['datetime'] = df_cmes.year\n",
      "for index in range(len(df_cmes)):\n",
      "    df_cmes.ix[index,'datetime'] = dt.datetime(df_cmes.ix[index,'year'],\n",
      "                                               df_cmes.ix[index,'month'],\n",
      "                                               df_cmes.ix[index,'day'],\n",
      "                                               df_cmes.ix[index,'hour'],\n",
      "                                               df_cmes.ix[index,'minute'])\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Clip to existing vector magnetogram data\n",
      "df_cmes = df_cmes[(df_cmes.year >= years[0]) & (df_cmes.month >= months[0])]\n",
      "df_cmes = df_cmes[(df_cmes.year <= years[-1]) & (df_cmes.month <= months[-1])]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Empty arrays to list indexes of events\n",
      "cmes = np.zeros(num_images, dtype=np.uint8)\n",
      "halos = np.zeros(num_images, dtype=np.uint8)\n",
      "start = 1\n",
      "for index2 in range(0,len(df_cmes)): \n",
      "    cur_row = df_cmes.iloc[index2]\n",
      "    for index in range(start, num_images):        \n",
      "        cur_datetime = dt.datetime(years[index],\n",
      "                                   months[index],\n",
      "                                   days[index],\n",
      "                                   hours[index],\n",
      "                                   minutes[index])\n",
      "       \n",
      "        if cur_datetime > cur_row.datetime:\n",
      "            break\n",
      "    cmes[index-1] = 1\n",
      "    if cur_row.halo == 1:\n",
      "        halos[index-1] = 1 \n",
      "        start = index-1\n",
      "        \n",
      "    if index2%100 == 0 and index2 > 0:\n",
      "        print str(index2) + ' of ' + str(len(df_cmes)) + ' CMEs processed'\n",
      "print 'Done'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create a column of time since the last CME\n",
      "# Note that it's not inclusive, i.e. even if a CME happened\n",
      "# on that datetime we still calculate the time since the next last\n",
      "# CME so that we can use it as a predictor\n",
      "time_since = np.zeros(num_images, dtype=np.uint8)\n",
      "time_since[0] = 1\n",
      "for index in range(1,num_images):\n",
      "    if cmes[index-1] == 1 or index == 1:\n",
      "        start_datetime = dt.datetime(years[index-1],\n",
      "                                   months[index-1],\n",
      "                                   days[index-1],\n",
      "                                   hours[index-1],\n",
      "                                   minutes[index-1]) \n",
      "    cur_datetime = dt.datetime(years[index],\n",
      "                               months[index],\n",
      "                               days[index],\n",
      "                               hours[index],\n",
      "                               minutes[index]) \n",
      "    time_since[index] = (cur_datetime - start_datetime).seconds/(60*15)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "quiet = np.zeros(num_images, dtype=np.uint8)\n",
      "indexes = np.where(cmes)[0]\n",
      "for index in range(0,len(indexes)-1):\n",
      "    start = indexes[index]\n",
      "    stop = indexes[index+1]\n",
      "    if (stop-start)/2 != 0:\n",
      "        quiet[indexes[index]+ (stop-start)/2] = 1\n",
      "        \n",
      "# quiet_tmp = np.ones(num_images, dtype=np.uint8)\n",
      "# quiet_tmp = quiet_tmp - cmes\n",
      "# random_list = sorted(random.sample(xrange(len(quiet_tmp)), 4000))\n",
      "# quiet = np.zeros(num_images, dtype=np.uint8)\n",
      "# quiet[random_list] = quiet_tmp[random_list]\n",
      "\n",
      "both = quiet + cmes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Number of pre-CME frames: ' + str(np.sum(cmes))\n",
      "print 'Total number of CMEs: ' + str(sum(df_cmes.CME==1))\n",
      "print 'Number of pre-halo frames: ' + str(np.sum(halos))\n",
      "print 'Total number of halos: ' + str(sum(df_cmes.halo==1))\n",
      "print 'Number of quiet frames: ' + str(np.sum(quiet))\n",
      "print 'Number of cme + quiet frames: ' + str(np.sum(both))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# dictionary_image  = masked_to_image(dictionary[0,:], sun_mask.ravel(), image_size)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.save('data/notebook_data/coded_images_32_512',coded_images)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# del all_images"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bins = 1000\n",
      "# training_X = bin_for_NB(coded_images,bins)\n",
      "training_X = coded_images\n",
      "# training_X = np.concatenate((training_X, np.reshape(time_since, [time_since.shape[0],1])), axis = 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# plt.hist(coded_images[1000,:])\n",
      "# plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import metrics\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.metrics import classification_report, roc_auc_score \n",
      "# X_split1, X_split2, y_split1, y_split2 = train_test_split(training_X, training_y, test_size=0.50)\n",
      "# del training_X, training_y\n",
      "X_train, X_test, y_train, y_test = train_test_split(training_X, cmes, test_size=0.30)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# If we have reduces the dimensionality then we now have negative floats\n",
      "# Require binning for multivariate bayes\n",
      "def bin_for_NB(array_in, bins):\n",
      "    array_out = np.zeros([array_in.shape[0],bins],dtype = np.uint8)\n",
      "    min_X = np.min(array_in)\n",
      "    max_X = np.max(array_in)\n",
      "    bin_width = (max_X - min_X)/(bins)\n",
      "    for b in range(bins):\n",
      "        bin_mask = np.sum((array_in >= min_X + bin_width*b) & (array_in < min_X + bin_width*(b+1)),axis=1)\n",
      "#         print bin_mask.shape\n",
      "        array_out[:,b] = bin_mask\n",
      "#     array_out[:,array_in == max_X] = b\n",
      "    \n",
      "    return array_out     "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# from sklearn.ensemble import RandomForestClassifier  \n",
      "# RF = RandomForestClassifier()\n",
      "\n",
      "\n",
      "# RF.fit(X_train,y_train)\n",
      "# y_predict_train = RF.predict(X_train)\n",
      "# y_predict_test = RF.predict(X_test)  \n",
      "# print RF.score(X_train,y_train)\n",
      "# print RF.score(X_test,y_test)\n",
      "# print metrics.classification_report(y_train, y_predict_train)\n",
      "# print metrics.classification_report(y_test, y_predict_test)\n",
      "# print roc_auc_score(y_train, y_predict_train)\n",
      "# print roc_auc_score(y_test, y_predict_test)\n",
      "# # print RF.feature_importances_\n",
      "# # for rank in sorted(importance):\n",
      "# #     print rank\n",
      "# # plt.scatter(training_X[:,1], training_y)\n",
      "# # predict_all = RF.predict(training_X) \n",
      "# # plt.hold\n",
      "# # plt.scatter(training_X[:,1],predict_all,color='r')\n",
      "# # plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.naive_bayes import GaussianNB \n",
      "\n",
      "MNB = GaussianNB()\n",
      "MNB.fit(X_train ,y_train)\n",
      "y_predict_train = MNB.predict(X_train )\n",
      "y_predict_test = MNB.predict(X_test )\n",
      "print 'R^2 train: ' + str(MNB.score(X_train ,y_train))\n",
      "print 'R^2 test: ' + str(MNB.score(X_test ,y_test))\n",
      "print metrics.classification_report(y_train, y_predict_train)\n",
      "print metrics.classification_report(y_test, y_predict_test)\n",
      "auc1= roc_auc_score(y_train, y_predict_train)\n",
      "auc2= roc_auc_score(y_test, y_predict_test)\n",
      "print 'Area Under Curve train: ' + str(auc1)\n",
      "print 'Area Under Curve test: ' + str(auc2)\n",
      "print 'Area Under Curve average: ' + str((auc1+auc2)/2)\n",
      "# print MNB.feature_log_prob_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# No timesince\n",
      "# Area Under Curve train: 0.600776302027\n",
      "# Area Under Curve test: 0.606887223362\n",
      "# Area Under Curve average: 0.603831762694"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# from sklearn.linear_model import LogisticRegression \n",
      "\n",
      "# MNB = LogisticRegression(penalty='l2')\n",
      "# MNB.fit(X_train ,y_train)\n",
      "# y_predict_train = MNB.predict(X_train )\n",
      "# y_predict_test = MNB.predict(X_test )\n",
      "# print MNB.score(X_train ,y_train)\n",
      "# print MNB.score(X_test ,y_test)\n",
      "# print metrics.classification_report(y_train, y_predict_train)\n",
      "# print metrics.classification_report(y_test, y_predict_test)\n",
      "# print roc_auc_score(y_train, y_predict_train)\n",
      "# print roc_auc_score(y_test, y_predict_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
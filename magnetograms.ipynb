{
 "metadata": {
  "name": "",
  "signature": "sha256:b1cc205a4ced44359f3b9cce95c4f203bb0f0fc41f615ba550bd7bc98c4ac660"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from time import time\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "import os\n",
      "import Image as im\n",
      "# import datetime as dt\n",
      "\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "from sklearn.metrics import classification_report\n",
      "from sklearn.metrics import confusion_matrix\n",
      "from sklearn.decomposition import RandomizedPCA\n",
      "from sklearn.svm import SVC\n",
      "\n",
      "# Images in file\n",
      "basedir = 'data/magnetograms/'\n",
      "flist = os.listdir(basedir)\n",
      "num_images = len(flist)\n",
      "\n",
      "#Make numpy arrays of pixes, years, months, days, hours, mins, CMEs\n",
      "#Make flatten mask\n",
      "\n",
      "count = 0\n",
      "for image_file in flist:\n",
      "    cur_file = image_file + basedir\n",
      "    cur_year = image_file[0:4]\n",
      "    cur_month = image_file[4:6]\n",
      "    cur_day = image_file[6:8]\n",
      "    cur_hour = image_file[9:11]\n",
      "    cur_minute = image_file[11:13]\n",
      "    print cur_year, cur_month, cur_day, cur_hour, cur_minute\n",
      "    count +=1\n",
      "    if count > 10:\n",
      "        break\n",
      "\n",
      "print flist[0]\n",
      "import Image\n",
      "myImage = im.open(basedir+ flist[0]);\n",
      "# myImage.show();\n",
      "\n",
      "print myImage.size\n",
      "print num_pics\n",
      "print myImage.getpixel((0,0))\n",
      "myImage = myImage.convert('L')\n",
      "print myImage.getpixel((0,0))\n",
      "test = np.asarray(myImage)\n",
      "print np.max(test)\n",
      "    \n",
      "\n",
      "# arr = np.zeros((L, 24576))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2010 05 01 00 00\n",
        "2010 05 01 00 15\n",
        "2010 05 01 00 30\n",
        "2010 05 01 00 45\n",
        "2010 05 01 01 00\n",
        "2010 05 01 01 15\n",
        "2010 05 01 01 30\n",
        "2010 05 01 01 45\n",
        "2010 05 01 02 00\n",
        "2010 05 01 02 15\n",
        "2010 05 01 02 30\n",
        "20100501_000000_M_512.jpg\n",
        "(512, 512)\n",
        "22920\n",
        "(0, 0, 0)\n",
        "0\n",
        "255\n"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# ###############################################################################\n",
      "# # Download the data, if not already on disk and load it as numpy arrays\n",
      "\n",
      "# lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n",
      "\n",
      "# # introspect the images arrays to find the shapes (for plotting)\n",
      "# n_samples, h, w = lfw_people.images.shape\n",
      "\n",
      "# # for machine learning we use the 2 data directly (as relative pixel\n",
      "# # positions info is ignored by this model)\n",
      "# X = lfw_people.data\n",
      "# n_features = X.shape[1]\n",
      "\n",
      "# # the label to predict is the id of the person\n",
      "# y = lfw_people.target\n",
      "# target_names = lfw_people.target_names\n",
      "# n_classes = target_names.shape[0]\n",
      "\n",
      "# print(\"Total dataset size:\")\n",
      "# print(\"n_samples: %d\" % n_samples)\n",
      "# print(\"n_features: %d\" % n_features)\n",
      "# print(\"n_classes: %d\" % n_classes)\n",
      "\n",
      "\n",
      "# ###############################################################################\n",
      "# # Split into a training set and a test set using a stratified k fold\n",
      "\n",
      "# # split into a training and testing set\n",
      "# X_train, X_test, y_train, y_test = train_test_split(\n",
      "#     X, y, test_size=0.25)\n",
      "\n",
      "\n",
      "# ###############################################################################\n",
      "# # Compute a PCA (eigenfaces) on the face dataset (treated as unlabeled\n",
      "# # dataset): unsupervised feature extraction / dimensionality reduction\n",
      "# n_components = 150\n",
      "\n",
      "# print(\"Extracting the top %d eigenfaces from %d faces\"\n",
      "#       % (n_components, X_train.shape[0]))\n",
      "# t0 = time()\n",
      "# pca = RandomizedPCA(n_components=n_components, whiten=True).fit(X_train)\n",
      "# print(\"done in %0.3fs\" % (time() - t0))\n",
      "\n",
      "# eigenfaces = pca.components_.reshape((n_components, h, w))\n",
      "\n",
      "# print(\"Projecting the input data on the eigenfaces orthonormal basis\")\n",
      "# t0 = time()\n",
      "# X_train_pca = pca.transform(X_train)\n",
      "# X_test_pca = pca.transform(X_test)\n",
      "# print(\"done in %0.3fs\" % (time() - t0))\n",
      "\n",
      "\n",
      "# ###############################################################################\n",
      "# # Train a SVM classification model\n",
      "\n",
      "# print(\"Fitting the classifier to the training set\")\n",
      "# t0 = time()\n",
      "# param_grid = {'C': [1e3, 5e3, 1e4, 5e4, 1e5],\n",
      "#               'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1], }\n",
      "# clf = GridSearchCV(SVC(kernel='rbf', class_weight='auto'), param_grid)\n",
      "# clf = clf.fit(X_train_pca, y_train)\n",
      "# print(\"done in %0.3fs\" % (time() - t0))\n",
      "# print(\"Best estimator found by grid search:\")\n",
      "# print(clf.best_estimator_)\n",
      "\n",
      "\n",
      "# ###############################################################################\n",
      "# # Quantitative evaluation of the model quality on the test set\n",
      "\n",
      "# print(\"Predicting people's names on the test set\")\n",
      "# t0 = time()\n",
      "# y_pred = clf.predict(X_test_pca)\n",
      "# print(\"done in %0.3fs\" % (time() - t0))\n",
      "\n",
      "# print(classification_report(y_test, y_pred, target_names=target_names))\n",
      "# print(confusion_matrix(y_test, y_pred, labels=range(n_classes)))\n",
      "\n",
      "\n",
      "# ###############################################################################\n",
      "# # Qualitative evaluation of the predictions using matplotlib\n",
      "\n",
      "# def plot_gallery(images, titles, h, w, n_row=3, n_col=4):\n",
      "#     \"\"\"Helper function to plot a gallery of portraits\"\"\"\n",
      "#     plt.figure(figsize=(1.8 * n_col, 2.4 * n_row))\n",
      "#     plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n",
      "#     for i in range(n_row * n_col):\n",
      "#         plt.subplot(n_row, n_col, i + 1)\n",
      "#         plt.imshow(images[i].reshape((h, w)), cmap=plt.cm.gray)\n",
      "#         plt.title(titles[i], size=12)\n",
      "#         plt.xticks(())\n",
      "#         plt.yticks(())\n",
      "\n",
      "\n",
      "# # plot the result of the prediction on a portion of the test set\n",
      "\n",
      "# def title(y_pred, y_test, target_names, i):\n",
      "#     pred_name = target_names[y_pred[i]].rsplit(' ', 1)[-1]\n",
      "#     true_name = target_names[y_test[i]].rsplit(' ', 1)[-1]\n",
      "#     return 'predicted: %s\\ntrue:      %s' % (pred_name, true_name)\n",
      "\n",
      "# prediction_titles = [title(y_pred, y_test, target_names, i)\n",
      "#                      for i in range(y_pred.shape[0])]\n",
      "\n",
      "# plot_gallery(X_test, prediction_titles, h, w)\n",
      "\n",
      "# # plot the gallery of the most significative eigenfaces\n",
      "\n",
      "# eigenface_titles = [\"eigenface %d\" % i for i in range(eigenfaces.shape[0])]\n",
      "# plot_gallery(eigenfaces, eigenface_titles, h, w)\n",
      "\n",
      "# plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
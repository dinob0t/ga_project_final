{
 "metadata": {
  "name": "",
  "signature": "sha256:67d0328920cdf0d713e4c832dcfe6c06bed08085f687fc3458a9782a4d40424b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from time import time\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "import os\n",
      "import Image as im\n",
      "import datetime as dt\n",
      "\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "from sklearn.metrics import classification_report\n",
      "from sklearn.metrics import confusion_matrix\n",
      "from sklearn.decomposition import RandomizedPCA\n",
      "from sklearn.svm import SVC\n",
      "\n",
      "# Images in file\n",
      "basedir = 'data/magnetograms/'\n",
      "flist = os.listdir(basedir)\n",
      "num_images = len(flist)\n",
      "\n",
      "def make_sun_mask(centre, radius, image_size):\n",
      "    sun_mask = np.zeros([image_size,image_size], dtype=np.uint8)\n",
      "    for i in range(image_size):\n",
      "        for j in range(image_size):\n",
      "            dist = np.sqrt((centre[0] - i)**2 + (centre[1] - j)**2)\n",
      "            if dist<= radius:\n",
      "                sun_mask[i,j] = 1\n",
      "    return sun_mask\n",
      "# Make sun mask\n",
      "image_size = 512\n",
      "sun_mask = make_sun_mask((255,255), 472/2, 512)\n",
      "# Flatten array\n",
      "sun_mask = np.ravel(sun_mask)\n",
      "\n",
      "years = np.zeros(num_images, dtype=np.int)\n",
      "months = np.zeros(num_images, dtype=np.int)\n",
      "days = np.zeros(num_images, dtype=np.int)\n",
      "hours = np.zeros(num_images, dtype=np.int)\n",
      "minutes = np.zeros(num_images, dtype=np.int)\n",
      "sun_discs = np.zeros([num_images,sum(sun_mask)], dtype=np.int)\n",
      "\n",
      "\n",
      "# myImage = np.asarray(myImage)\n",
      "# print sun_mask.shape\n",
      "# print myImage.shape\n",
      "# myImage = myImage + sun_mask\n",
      "# # myImage = np.max(myImage,0)\n",
      "# myImage = Image.fromarray(myImage, 'RGB')\n",
      "# myImage.show()\n",
      "\n",
      "    \n",
      "# import Image\n",
      "# myImage = im.open(basedir+ flist[0]);\n",
      "# myImage.show();\n",
      "\n",
      "# print myImage.size\n",
      "# print num_pics\n",
      "# print myImage.getpixel((0,0))\n",
      "# myImage = myImage.convert('L')\n",
      "# print myImage.getpixel((0,0))\n",
      "# test = np.asarray(myImage)\n",
      "# print np.max(test)\n",
      "    \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "count = 0\n",
      "for image_file in flist:    \n",
      "    years[count] = image_file[0:4]\n",
      "    months[count] = image_file[4:6]\n",
      "    days[count] = image_file[6:8]\n",
      "    hours[count] = image_file[9:11]\n",
      "    minutes[count] = image_file[11:13]\n",
      "    \n",
      "    cur_file = basedir + image_file  \n",
      "    # Read image, convert to greyscale, convert to np array\n",
      "    cur_image = np.asarray(im.open(cur_file).convert('L'))\n",
      "    cur_image = np.ravel(cur_image)\n",
      "    cur_image = cur_image[sun_mask == 1]\n",
      "    sun_discs[count,:] = cur_image\n",
      "    if count%1000 == 0 and count > 0:\n",
      "        print str(count) + ' of ' + str(num_images) +' , File: '+ image_file \n",
      "    count +=1  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1000 of 22920 , File: 20100511_113000_M_512.jpg\n",
        "2000 of 22920 , File: 20100521_234500_M_512.jpg"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3000 of 22920 , File: 20100601_110000_M_512.jpg"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4000 of 22920 , File: 20100611_211500_M_512.jpg"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5000 of 22920 , File: 20100622_071500_M_512.jpg"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6000 of 22920 , File: 20100702_180000_M_512.jpg"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7000 of 22920 , File: 20100713_051500_M_512.jpg"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "8000 of 22920 , File: 20100724_091500_M_512.jpg"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "9000 of 22920 , File: 20100803_193000_M_512.jpg"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10000 of 22920 , File: 20100814_060000_M_512.jpg"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "11000 of 22920 , File: 20100824_163000_M_512.jpg"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12000 of 22920 , File: 20100904_040000_M_512.jpg"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "13000 of 22920 , File: 20100914_151500_M_512.jpg"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "14000 of 22920 , File: 20100926_033000_M_512.jpg"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "15000 of 22920 , File: 20101008_020000_M_512.jpg"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "16000 of 22920 , File: 20101018_144500_M_512.jpg"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "17000 of 22920 , File: 20101029_071500_M_512.jpg"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "18000 of 22920 , File: 20101109_033000_M_512.jpg"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "19000 of 22920 , File: 20101119_140000_M_512.jpg"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "20000 of 22920 , File: 20101130_000000_M_512.jpg"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "21000 of 22920 , File: 20101210_113000_M_512.jpg"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "22000 of 22920 , File: 20101221_130000_M_512.jpg"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#####################################################################################\n",
      "# Import lasco CME catalogue - \n",
      "# Date\n",
      "# Time\n",
      "# Central_PA : Central size [deg] \n",
      "# Width : Angular width [deg]\n",
      "# L_speed : linear speed\n",
      "# 2nd_o_speed : 2nd order speed fit\n",
      "# 2nd_o_speed_20R : 2nd order speed fit @ 20R\n",
      "# Accel : Acceleration\n",
      "# Mass :\n",
      "# KE : Kinetic energy\n",
      "# MPA : Measurement position angle\n",
      "df_cmes = pd.read_csv(\"cme_catalogue.md\",delim_whitespace=True,error_bad_lines =False, warn_bad_lines=False )\n",
      "df_cmes.drop(['Comment1','Comment2', 'Comment3'], axis=1, inplace=True)\n",
      "df_cmes[['year','month','day']] = df_cmes.Date.str.extract('(\\d\\d\\d\\d)/(\\d\\d)/(\\d\\d)')\n",
      "df_cmes[['hour','minute']] = df_cmes.Time.str.extract('(\\d\\d):(\\d\\d)')\n",
      "\n",
      "df_cmes.drop(['Date','Time','KE','Mass','MPA'],axis=1, inplace=True)    \n",
      "df_cmes['CME'] = 1\n",
      "df_cmes['halo'] = df_cmes.Central_PA\n",
      "df_cmes.ix[df_cmes.halo!='Halo', 'halo'] = 0\n",
      "df_cmes.ix[df_cmes.halo=='Halo', 'halo'] = 1\n",
      "df_cmes.ix[df_cmes.Central_PA=='Halo', 'Central_PA'] = 360\n",
      "# Make the features integer\n",
      "for feature in df_cmes.columns:\n",
      "    df_cmes[feature] = df_cmes[feature].astype(int)\n",
      "# Sort all on year -> month->day\n",
      "df_cmes = df_cmes.sort(columns=['year','month','day'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 137
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_cmes['datetime'] = df_cmes.year\n",
      "for index in range(len(df_cmes)):\n",
      "    df_cmes.ix[index,'datetime'] = dt.datetime(df_cmes.ix[index,'year'],\n",
      "                                               df_cmes.ix[index,'month'],\n",
      "                                               df_cmes.ix[index,'day'],\n",
      "                                               df_cmes.ix[index,'hour'],\n",
      "                                               df_cmes.ix[index,'minute'])\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 138
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_cmes = df_cmes[df_cmes.year >= min(years)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 139
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cmes = np.zeros(num_images, dtype=np.int)\n",
      "halos = np.zeros(num_images, dtype=np.int)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 146
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "start = 1\n",
      "for index in range(num_images):\n",
      "    cur_datetime = dt.datetime(years[index],\n",
      "                               months[index],\n",
      "                               days[index],\n",
      "                               hours[index],\n",
      "                               minutes[index])\n",
      "    for index2 in range(start-1,len(df_cmes)-1):\n",
      "        closest_row = df_cmes.iloc[index2]\n",
      "        if (closest_row.datetime > cur_datetime):\n",
      "            break\n",
      "    time_diff = (closest_row.datetime - cur_datetime).seconds\n",
      "    # If CME occurs within 45 mins of frame\n",
      "    if time_diff <=30*60:\n",
      "        start = index2\n",
      "        cmes[index] = 1\n",
      "        if closest_row.halo == 1:\n",
      "            halos[index] = 1\n",
      "    if index%1000 == 0 and index > 0:\n",
      "        print str(index) + ' of ' + str(num_images)        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1000 of 22920\n",
        "2000 of 22920"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3000 of 22920"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4000 of 22920"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5000 of 22920"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6000 of 22920"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7000 of 22920"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "8000 of 22920"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "9000 of 22920"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10000 of 22920"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "11000 of 22920"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12000 of 22920"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "13000 of 22920"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "14000 of 22920"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "15000 of 22920"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "16000 of 22920"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "17000 of 22920"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "18000 of 22920"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "19000 of 22920"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "20000 of 22920"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "21000 of 22920"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "22000 of 22920"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 147
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.scatter(range(len(cmes)),halos)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 151
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def masked_to_image(masked, sun_mask, image_size):\n",
      "    sun_image = np.zeros([image_size**2])\n",
      "    sun_image[sun_mask==1] = masked\n",
      "    sun_image = sun_image.reshape([image_size, image_size])\n",
      "    return sun_image   \n",
      "n_components = 10\n",
      "t0 = time()\n",
      "pca = RandomizedPCA(n_components=n_components, whiten=True).fit(sun_discs[halos==1,:])\n",
      "print(\"done in %0.3fs\" % (time() - t0))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done in 0.842s\n"
       ]
      }
     ],
     "prompt_number": 165
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "eigensuns = pca.components_.reshape((n_components, 174921))\n",
      "for n in range(n_components):\n",
      "    cur_sun = masked_to_image(eigensuns[n,:], sun_mask, image_size)\n",
      "    plt.imshow(cur_sun, cmap=plt.cm.gray)\n",
      "    plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 166
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# ###############################################################################\n",
      "# # Download the data, if not already on disk and load it as numpy arrays\n",
      "\n",
      "# lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n",
      "\n",
      "# # introspect the images arrays to find the shapes (for plotting)\n",
      "# n_samples, h, w = lfw_people.images.shape\n",
      "\n",
      "# # for machine learning we use the 2 data directly (as relative pixel\n",
      "# # positions info is ignored by this model)\n",
      "# X = lfw_people.data\n",
      "# n_features = X.shape[1]\n",
      "\n",
      "# # the label to predict is the id of the person\n",
      "# y = lfw_people.target\n",
      "# target_names = lfw_people.target_names\n",
      "# n_classes = target_names.shape[0]\n",
      "\n",
      "# print(\"Total dataset size:\")\n",
      "# print(\"n_samples: %d\" % n_samples)\n",
      "# print(\"n_features: %d\" % n_features)\n",
      "# print(\"n_classes: %d\" % n_classes)\n",
      "\n",
      "\n",
      "# ###############################################################################\n",
      "# # Split into a training set and a test set using a stratified k fold\n",
      "\n",
      "# # split into a training and testing set\n",
      "# X_train, X_test, y_train, y_test = train_test_split(\n",
      "#     X, y, test_size=0.25)\n",
      "\n",
      "\n",
      "# ###############################################################################\n",
      "# # Compute a PCA (eigenfaces) on the face dataset (treated as unlabeled\n",
      "# # dataset): unsupervised feature extraction / dimensionality reduction\n",
      "# n_components = 150\n",
      "\n",
      "# print(\"Extracting the top %d eigenfaces from %d faces\"\n",
      "#       % (n_components, X_train.shape[0]))\n",
      "# t0 = time()\n",
      "# pca = RandomizedPCA(n_components=n_components, whiten=True).fit(X_train)\n",
      "# print(\"done in %0.3fs\" % (time() - t0))\n",
      "\n",
      "# eigenfaces = pca.components_.reshape((n_components, h, w))\n",
      "\n",
      "# print(\"Projecting the input data on the eigenfaces orthonormal basis\")\n",
      "# t0 = time()\n",
      "# X_train_pca = pca.transform(X_train)\n",
      "# X_test_pca = pca.transform(X_test)\n",
      "# print(\"done in %0.3fs\" % (time() - t0))\n",
      "\n",
      "\n",
      "# ###############################################################################\n",
      "# # Train a SVM classification model\n",
      "\n",
      "# print(\"Fitting the classifier to the training set\")\n",
      "# t0 = time()\n",
      "# param_grid = {'C': [1e3, 5e3, 1e4, 5e4, 1e5],\n",
      "#               'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1], }\n",
      "# clf = GridSearchCV(SVC(kernel='rbf', class_weight='auto'), param_grid)\n",
      "# clf = clf.fit(X_train_pca, y_train)\n",
      "# print(\"done in %0.3fs\" % (time() - t0))\n",
      "# print(\"Best estimator found by grid search:\")\n",
      "# print(clf.best_estimator_)\n",
      "\n",
      "\n",
      "# ###############################################################################\n",
      "# # Quantitative evaluation of the model quality on the test set\n",
      "\n",
      "# print(\"Predicting people's names on the test set\")\n",
      "# t0 = time()\n",
      "# y_pred = clf.predict(X_test_pca)\n",
      "# print(\"done in %0.3fs\" % (time() - t0))\n",
      "\n",
      "# print(classification_report(y_test, y_pred, target_names=target_names))\n",
      "# print(confusion_matrix(y_test, y_pred, labels=range(n_classes)))\n",
      "\n",
      "\n",
      "# ###############################################################################\n",
      "# # Qualitative evaluation of the predictions using matplotlib\n",
      "\n",
      "# def plot_gallery(images, titles, h, w, n_row=3, n_col=4):\n",
      "#     \"\"\"Helper function to plot a gallery of portraits\"\"\"\n",
      "#     plt.figure(figsize=(1.8 * n_col, 2.4 * n_row))\n",
      "#     plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n",
      "#     for i in range(n_row * n_col):\n",
      "#         plt.subplot(n_row, n_col, i + 1)\n",
      "#         plt.imshow(images[i].reshape((h, w)), cmap=plt.cm.gray)\n",
      "#         plt.title(titles[i], size=12)\n",
      "#         plt.xticks(())\n",
      "#         plt.yticks(())\n",
      "\n",
      "\n",
      "# # plot the result of the prediction on a portion of the test set\n",
      "\n",
      "# def title(y_pred, y_test, target_names, i):\n",
      "#     pred_name = target_names[y_pred[i]].rsplit(' ', 1)[-1]\n",
      "#     true_name = target_names[y_test[i]].rsplit(' ', 1)[-1]\n",
      "#     return 'predicted: %s\\ntrue:      %s' % (pred_name, true_name)\n",
      "\n",
      "# prediction_titles = [title(y_pred, y_test, target_names, i)\n",
      "#                      for i in range(y_pred.shape[0])]\n",
      "\n",
      "# plot_gallery(X_test, prediction_titles, h, w)\n",
      "\n",
      "# # plot the gallery of the most significative eigenfaces\n",
      "\n",
      "# eigenface_titles = [\"eigenface %d\" % i for i in range(eigenfaces.shape[0])]\n",
      "# plot_gallery(eigenfaces, eigenface_titles, h, w)\n",
      "\n",
      "# plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Need to round catalogue down to nearest time that exists\n",
      "# Can we predict largers ones better?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
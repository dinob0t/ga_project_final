{
 "metadata": {
  "name": "",
  "signature": "sha256:1fef130e8b4a8da366e2268045d4e054e43e9b1f4c1b3dda9cfea7329efdd95c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from time import time\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "import os\n",
      "import Image as im\n",
      "import datetime as dt\n",
      "\n",
      "# Images in file\n",
      "basedir = 'data/all_256/'\n",
      "flist = os.listdir(basedir)\n",
      "flist = sorted(flist)\n",
      "num_images = len(flist)\n",
      "\n",
      "# Create mask array to select only within solar disk\n",
      "def make_sun_mask(centre, radius, image_size):\n",
      "    sun_mask = np.zeros([image_size,image_size], dtype=np.uint8)\n",
      "    for i in range(image_size):\n",
      "        for j in range(image_size):\n",
      "            dist = np.sqrt((centre[0] - i)**2 + (centre[1] - j)**2)\n",
      "            if dist<= radius:\n",
      "                sun_mask[i,j] = 1\n",
      "    return sun_mask\n",
      "# Make sun mask\n",
      "# Hi-res images\n",
      "# image_size = 512\n",
      "# centre = (255,255)\n",
      "# radius = 472/2\n",
      "\n",
      "# Low-res images\n",
      "image_size = 256\n",
      "centre = (127,127)\n",
      "radius = 234/2\n",
      "\n",
      "sun_mask = make_sun_mask(centre, radius, image_size)\n",
      "# Flatten array\n",
      "sun_mask = np.ravel(sun_mask)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Initialise arrays\n",
      "years = np.zeros(num_images, dtype=np.uint16)\n",
      "months = np.zeros(num_images, dtype=np.uint8)\n",
      "days = np.zeros(num_images, dtype=np.uint8)\n",
      "hours = np.zeros(num_images, dtype=np.uint8)\n",
      "minutes = np.zeros(num_images, dtype=np.uint8)\n",
      "sun_discs = np.zeros([num_images,sum(sun_mask)], dtype=np.int8)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get all vector magnetogram files\n",
      "count = 0\n",
      "for image_file in flist:    \n",
      "    years[count] = image_file[0:4]\n",
      "    months[count] = image_file[4:6]\n",
      "    days[count] = image_file[6:8]\n",
      "    hours[count] = image_file[9:11]\n",
      "    minutes[count] = image_file[11:13]\n",
      "    \n",
      "    cur_file = basedir + image_file  \n",
      "    # Read image, convert to greyscale, convert to np array\n",
      "    cur_image = np.asarray(im.open(cur_file).convert('L'))\n",
      "    cur_image = np.ravel(cur_image)\n",
      "    cur_image = cur_image[sun_mask == 1]\n",
      "    # Subtract off mean for PCA later\n",
      "    sun_discs[count,:] = cur_image\n",
      "    if count%10000 == 0 and count > 0:\n",
      "        print str(count) + ' of ' + str(num_images) +' , File: '+ image_file \n",
      "    count +=1 \n",
      "print 'Done'\n",
      "column_mean = np.mean(sun_discs, axis = 0)\n",
      "for i in range(num_images):\n",
      "    sun_discs[i,:] = sun_discs[i,:] - column_mean\n",
      "    if i%1000 == 0:\n",
      "        print i\n",
      "np.save('data/notebook_data/sun_discs',sun_discs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10000 of 126144 , File: 20100814_054500_M_256.jpg\n",
        "20000 of 126144 , File: 20101129_230000_M_256.jpg"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "30000 of 126144 , File: 20110316_220000_M_256.jpg"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "40000 of 126144 , File: 20110701_074500_M_256.jpg"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "50000 of 126144 , File: 20111016_021500_M_256.jpg"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "60000 of 126144 , File: 20120129_120000_M_256.jpg"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "70000 of 126144 , File: 20120515_144500_M_256.jpg"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "80000 of 126144 , File: 20120828_071500_M_256.jpg"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "90000 of 126144 , File: 20121213_001500_M_256.jpg"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "100000 of 126144 , File: 20130329_181500_M_256.jpg"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "110000 of 126144 , File: 20130713_053000_M_256.jpg"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "120000 of 126144 , File: 20131028_180000_M_256.jpg"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Done"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "8000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "9000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "11000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "13000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "14000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "15000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "16000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "17000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "18000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "19000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "20000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "21000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "22000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "23000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "24000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "25000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "26000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "27000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "28000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "29000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "30000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "31000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "32000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "33000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "34000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "35000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "36000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "37000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "38000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "39000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "40000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "41000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "42000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "43000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "44000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "45000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "46000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "47000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "48000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "49000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "50000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "51000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "52000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "53000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "54000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "55000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "56000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "57000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "58000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "59000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "60000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "61000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "62000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "63000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "64000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "65000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "66000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "67000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "68000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "69000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "70000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "71000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "72000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "73000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "74000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "75000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "76000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "77000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "78000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "79000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "80000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "81000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "82000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "83000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "84000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "85000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "86000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "87000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "88000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "89000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "90000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "91000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "92000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "93000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "94000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "95000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "96000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "97000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "98000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "99000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "101000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "102000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "103000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "104000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "105000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "106000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "107000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "108000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "109000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "110000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "111000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "112000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "113000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "114000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "115000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "116000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "117000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "118000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "119000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "120000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "121000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "122000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "123000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "124000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "125000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "126000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#####################################################################################\n",
      "# Import lasco CME catalogue - \n",
      "# Date\n",
      "# Time\n",
      "# Central_PA : Central size [deg] \n",
      "# Width : Angular width [deg]\n",
      "# L_speed : linear speed\n",
      "# 2nd_o_speed : 2nd order speed fit\n",
      "# 2nd_o_speed_20R : 2nd order speed fit @ 20R\n",
      "# Accel : Acceleration\n",
      "# Mass :\n",
      "# KE : Kinetic energy\n",
      "# MPA : Measurement position angle\n",
      "df_cmes = pd.read_csv(\"cme_catalogue.md\",delim_whitespace=True,error_bad_lines =False, warn_bad_lines=False )\n",
      "df_cmes.drop(['Comment1','Comment2', 'Comment3'], axis=1, inplace=True)\n",
      "df_cmes[['year','month','day']] = df_cmes.Date.str.extract('(\\d\\d\\d\\d)/(\\d\\d)/(\\d\\d)')\n",
      "df_cmes[['hour','minute']] = df_cmes.Time.str.extract('(\\d\\d):(\\d\\d)')\n",
      "\n",
      "df_cmes.drop(['Date','Time','KE','Mass','MPA'],axis=1, inplace=True)    \n",
      "df_cmes['CME'] = 1\n",
      "df_cmes['halo'] = df_cmes.Central_PA\n",
      "df_cmes.ix[df_cmes.halo!='Halo', 'halo'] = 0\n",
      "df_cmes.ix[df_cmes.halo=='Halo', 'halo'] = 1\n",
      "df_cmes.ix[df_cmes.Central_PA=='Halo', 'Central_PA'] = 360\n",
      "# Make the features integer\n",
      "for feature in df_cmes.columns:\n",
      "    df_cmes[feature] = df_cmes[feature].astype(int)\n",
      "# Sort all on year -> month->day\n",
      "df_cmes = df_cmes.sort(columns=['year','month','day'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Make datetime object in a new columns\n",
      "df_cmes['datetime'] = df_cmes.year\n",
      "for index in range(len(df_cmes)):\n",
      "    df_cmes.ix[index,'datetime'] = dt.datetime(df_cmes.ix[index,'year'],\n",
      "                                               df_cmes.ix[index,'month'],\n",
      "                                               df_cmes.ix[index,'day'],\n",
      "                                               df_cmes.ix[index,'hour'],\n",
      "                                               df_cmes.ix[index,'minute'])\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Clip to existing vector magnetogram data\n",
      "df_cmes = df_cmes[(df_cmes.year >= years[0]) & (df_cmes.month >= months[0])]\n",
      "df_cmes = df_cmes[(df_cmes.year <= years[-1]) & (df_cmes.month <= months[-1])]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Empty arrays to list indexes of events\n",
      "cmes = np.zeros(num_images, dtype=np.uint8)\n",
      "halos = np.zeros(num_images, dtype=np.uint8)\n",
      "start = 1\n",
      "for index2 in range(0,len(df_cmes)): \n",
      "    cur_row = df_cmes.iloc[index2]\n",
      "    for index in range(start, num_images):        \n",
      "        cur_datetime = dt.datetime(years[index],\n",
      "                                   months[index],\n",
      "                                   days[index],\n",
      "                                   hours[index],\n",
      "                                   minutes[index])\n",
      "       \n",
      "        if cur_datetime > cur_row.datetime:\n",
      "            break\n",
      "    cmes[index-1] = 1\n",
      "    if cur_row.halo == 1:\n",
      "        halos[index-1] = 1 \n",
      "        start = index-1\n",
      "        \n",
      "    if index2%100 == 0 and index2 > 0:\n",
      "        print str(index2) + ' of ' + str(len(df_cmes)) + ' CMEs processed'\n",
      "print 'Done'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "100 of 2852 CMEs processed\n",
        "200 of 2852 CMEs processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "300 of 2852 CMEs processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "400 of 2852 CMEs processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "500 of 2852 CMEs processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "600 of 2852 CMEs processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "700 of 2852 CMEs processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "800 of 2852 CMEs processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "900 of 2852 CMEs processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1000 of 2852 CMEs processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1100 of 2852 CMEs processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1200 of 2852 CMEs processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1300 of 2852 CMEs processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1400 of 2852 CMEs processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1500 of 2852 CMEs processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1600 of 2852 CMEs processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1700 of 2852 CMEs processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1800 of 2852 CMEs processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1900 of 2852 CMEs processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2000 of 2852 CMEs processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2100 of 2852 CMEs processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2200 of 2852 CMEs processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2300 of 2852 CMEs processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2400 of 2852 CMEs processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2500 of 2852 CMEs processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2600 of 2852 CMEs processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2700 of 2852 CMEs processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2800 of 2852 CMEs processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Done"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create a column of time since the last CME\n",
      "# Note that it's not inclusive, i.e. even if a CME happened\n",
      "# on that datetime we still calculate the time since the next last\n",
      "# CME so that we can use it as a predictor\n",
      "time_since = np.zeros(num_images, dtype=np.uint8)\n",
      "time_since[0] = 1\n",
      "for index in range(1,num_images):\n",
      "    if cmes[index-1] == 1 or index == 1:\n",
      "        start_datetime = dt.datetime(years[index-1],\n",
      "                                   months[index-1],\n",
      "                                   days[index-1],\n",
      "                                   hours[index-1],\n",
      "                                   minutes[index-1]) \n",
      "    cur_datetime = dt.datetime(years[index],\n",
      "                               months[index],\n",
      "                               days[index],\n",
      "                               hours[index],\n",
      "                               minutes[index]) \n",
      "    time_since[index] = (cur_datetime - start_datetime).seconds/(60*15)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# # Select non-CME frames - this biases model to choosing quiet times outside\n",
      "# # of the max solar cycle\n",
      "# quiet = np.zeros(num_images, dtype=np.uint8)\n",
      "# # Length of quiet intervals (approx quiet_thresh*15min)\n",
      "# quiet_thresh = 40\n",
      "# for index in range(num_images-1):\n",
      "#     if index%1000 == 0:\n",
      "#         print index\n",
      "#     if time_since[index] >=quiet_thresh:\n",
      "#         for index2 in range(index+1, num_images):\n",
      "#             if time_since[index2] > quiet_thresh:\n",
      "#                 if time_since[index2] >= quiet_thresh*2:\n",
      "#                     quiet[index] = 1\n",
      "#                     break\n",
      "#             else:\n",
      "#                 break\n",
      "\n",
      "# both = np.array(np.ceil(np.divide([cmes + quiet],2.0)),dtype=np.uint8)\n",
      "# both = both.reshape(both.shape[1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "quiet = np.zeros(num_images, dtype=np.uint8)\n",
      "indexes = np.where(cmes)[0]\n",
      "for index in range(0,len(indexes)-1):\n",
      "    start = indexes[index]\n",
      "    stop = indexes[index+1]\n",
      "    if (stop-start)/2 != 0:\n",
      "        quiet[indexes[index]+ (stop-start)/2] = 1\n",
      "        \n",
      "# quiet_tmp = np.ones(num_images, dtype=np.uint8)\n",
      "# quiet_tmp = quiet_tmp - cmes\n",
      "# random_list = sorted(random.sample(xrange(len(quiet_tmp)), 4000))\n",
      "# quiet = np.zeros(num_images, dtype=np.uint8)\n",
      "# quiet[random_list] = quiet_tmp[random_list]\n",
      "\n",
      "both = quiet + cmes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Number of pre-CME frames: ' + str(np.sum(cmes))\n",
      "print 'Total number of CMEs: ' + str(sum(df_cmes.CME==1))\n",
      "print 'Number of pre-halo frames: ' + str(np.sum(halos))\n",
      "print 'Total number of halos: ' + str(sum(df_cmes.halo==1))\n",
      "print 'Number of quiet frames: ' + str(np.sum(quiet))\n",
      "print 'Number of cme + quiet frames: ' + str(np.sum(both))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of pre-CME frames: 2794\n",
        "Total number of CMEs: 2852\n",
        "Number of pre-halo frames: 134\n",
        "Total number of halos: 134\n",
        "Number of quiet frames: 2734\n",
        "Number of cme + quiet frames: 5528\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Un-mask and reshape array for plotting\n",
      "def masked_to_image(masked, sun_mask, image_size):\n",
      "    sun_image = np.zeros([image_size**2])\n",
      "    sun_image[sun_mask==1] = masked\n",
      "    sun_image = sun_image.reshape([image_size, image_size])\n",
      "    return sun_image\n",
      "\n",
      "def plot_gallery(images, titles, h, w):\n",
      "    \"\"\"Helper function to plot a gallery of portraits\"\"\"\n",
      "    n_components = images.shape[0]\n",
      "    n_col = int(np.sqrt(n_components)) + np.ceil(np.sqrt(n_components)%1)\n",
      "    n_row = int(np.sqrt(n_components)) +np.ceil(np.sqrt(n_components)%1)\n",
      "    plt.figure(figsize=(1.8 * n_col, 2.4 * n_row))\n",
      "    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=0.2, wspace=0.2)\n",
      "    for i in range(n_components):\n",
      "        plt.subplot(n_row, n_col, i + 1)\n",
      "        plt.imshow(images[i,:,:], cmap=plt.cm.gray)\n",
      "        plt.title(titles[i], size=14)\n",
      "        plt.xticks(())\n",
      "        plt.yticks(())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Number of PCA components\n",
      "def plot_PCAS(sun_discs, event_array, n_components, analysis_type):\n",
      "    from sklearn.decomposition import PCA,RandomizedPCA \n",
      "    t0 = time()\n",
      "    if analysis_type == 'PCA':\n",
      "        pca = PCA(n_components=n_components, whiten=True).fit(sun_discs[event_array==1,:])\n",
      "    else:\n",
      "        pca = RandomizedPCA(n_components=n_components,  whiten=True).fit(sun_discs[event_array==1,:])\n",
      "    print(\"done in %0.3fs\" % (time() - t0))\n",
      "    eigensuns = np.zeros([n_components,image_size,image_size])\n",
      "    evr = pca.explained_variance_ratio_\n",
      "    for n in range(n_components):\n",
      "        eigensuns[n,:,:] = masked_to_image((pca.components_)[n,:], sun_mask, image_size)\n",
      "    eigensuns_titles = [\"Eigensun %d (evr=%.4f)\" % (i) for i in zip(range(eigensuns.shape[0]),evr)]\n",
      "    plot_gallery(eigensuns, eigensuns_titles, image_size, image_size)\n",
      "    plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Train PCA model\n",
      "def train_reduce_dimensionality(n_components):\n",
      "    from sklearn.decomposition import RandomizedPCA\n",
      "    import random\n",
      "    random_list = sorted(random.sample(xrange(sun_discs.shape[0]), sun_discs.shape[0]/10))\n",
      "    pca = RandomizedPCA(n_components=n_components, whiten=True,random_state=42).fit(sun_discs[random_list,:])\n",
      "#     print 'Explained variance ratios: ' + str(pca.explained_variance_ratio_)\n",
      "    return pca, pca.explained_variance_ratio_\n",
      "# Reduce sun_disc dimensionality\n",
      "def reduce_dimensionality(pca_model, array_in):\n",
      "    array_out = pca_model.transform(array_in)\n",
      "    return array_out"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pca, evr = train_reduce_dimensionality(100)\n",
      "# plt.plot(range(len(evr)), np.cumsum(evr))\n",
      "# plt.xlabel('PCA number',size=14)\n",
      "# plt.ylabel('Cumulative variance explained',size=14)\n",
      "# plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# plt.plot(range(100), np.cumsum(ssim_pca_cmes.explained_variance_ratio_))\n",
      "# plt.xlabel('PCA number',size=14)\n",
      "# plt.ylabel('Cumulative variance explained',size=14)\n",
      "# plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 285
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# plt.plot(range(len(evr)), (evr))\n",
      "# plt.xlabel('PCA number',size=14)\n",
      "# plt.ylabel('Variance explained',size=14)\n",
      "# plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from skimage.measure import structural_similarity as ssim\n",
      "from sklearn.decomposition import RandomizedPCA\n",
      "ssim_pca_cmes = RandomizedPCA(n_components=100, whiten=True,random_state=42).fit(sun_discs[cmes==1,:])\n",
      "ssim_pca_quiet = RandomizedPCA(n_components=100, whiten=True,random_state=42).fit(sun_discs[quiet==1,:])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# np.correlate(sun_discs[0,:], ssim_pca_cmes.components_[2])\n",
      "# # np.correlate()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 317,
       "text": [
        "array([ 0.10413853])"
       ]
      }
     ],
     "prompt_number": 317
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# sun_discs = np.load('data/notebook_data/sun_discs.npy')\n",
      "ssim_score = np.zeros([num_images,10],dtype=np.uint8)\n",
      "for i in range(num_images):\n",
      "    image_i = sun_discs[i,:]\n",
      "    for j in range(10):\n",
      "#         like_quiet = ssim(image_i,masked_to_image(ssim_pca_quiet.components_[j], sun_mask, image_size))\n",
      "#         like_cme = ssim(image_i,masked_to_image(ssim_pca_cmes.components_[j], sun_mask, image_size))\n",
      "#         print like_quiet, like_cme\n",
      "        like_quiet = np.correlate(image_i, ssim_pca_quiet.components_[j])\n",
      "        like_cme = np.correlate(image_i, ssim_pca_cmes.components_[j])    \n",
      "        if abs(like_quiet) < abs(like_cme):\n",
      "            ssim_score[i,j] = 1\n",
      "    if i%1000 == 0:\n",
      "        print i\n",
      "np.save('data/notebook_data/ssim_score',ssim_score)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n",
        "1000"
       ]
      }
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Reduce dimensionality in chunks (running out of memory!)\n",
      "sun_discs_rd = np.zeros([num_images,pca.components_.shape[0]], dtype=np.float32)\n",
      "chunk_size = 5000\n",
      "chunks = sun_discs.shape[0]/chunk_size\n",
      "for chunk in range(chunks):\n",
      "    sun_discs_rd[chunk_size*(chunk):chunk_size*(chunk+1),:] = reduce_dimensionality(pca, sun_discs[0:chunk_size,:])\n",
      "    sun_discs = sun_discs[chunk_size:,:]\n",
      "    print str(chunk) + ' of ' + str(chunks)\n",
      "sun_discs_rd[chunk_size*(chunk+1):num_images,:] = reduce_dimensionality(pca, sun_discs)\n",
      "del sun_discs\n",
      "np.save('data/notebook_data/sun_discs_rd_1000',sun_discs_rd)\n",
      "np.save('data/notebook_data/pca_model',pca)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0 of 25\n",
        "1 of 25"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2 of 25"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3 of 25"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4 of 25"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5 of 25"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6 of 25"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7 of 25"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "8 of 25"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "9 of 25"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10 of 25"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "11 of 25"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12 of 25"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "13 of 25"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "14 of 25"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "15 of 25"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "16 of 25"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "17 of 25"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "18 of 25"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "19 of 25"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "20 of 25"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "21 of 25"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "22 of 25"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "23 of 25"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "24 of 25"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# mode = 'load'\n",
      "# if mode == 'save':\n",
      "#     np.save('data/notebook_data/years',years)\n",
      "#     np.save('data/notebook_data/months',months)\n",
      "#     np.save('data/notebook_data/days',days)\n",
      "#     np.save('data/notebook_data/hours',hours)    \n",
      "#     np.save('data/notebook_data/minutes',minutes)\n",
      "#     np.save('data/notebook_data/cmes',cmes)\n",
      "#     np.save('data/notebook_data/halos',halos)\n",
      "#     np.save('data/notebook_data/both',both)\n",
      "#     np.save('data/notebook_data/quiet',quiet)\n",
      "#     np.save('data/notebook_data/sun_discs',sun_discs)    \n",
      "#     np.save('data/notebook_data/time_since',time_since)\n",
      "# #     np.save('data/notebook_data/training_y',training_y)\n",
      "# #     np.save('data/notebook_data/training_X',training_X)\n",
      "#     del years, months, days, hours, minutes, cmes, halos, quiet, time_since\n",
      "# elif mode=='load': \n",
      "# #     training_y = np.load('data/notebook_data/training_y.npy')\n",
      "# #     training_X = np.load('data/notebook_data/training_X.npy')\n",
      "#     both = np.load('data/notebook_data/both.npy')\n",
      "#     sun_discs = np.load('data/notebook_data/sun_discs.npy')\n",
      "#     years = np.load('data/notebook_data/years.npy')\n",
      "#     months = np.load('data/notebook_data/months.npy')\n",
      "#     days = np.load('data/notebook_data/days.npy')\n",
      "#     hours = np.load('data/notebook_data/hours.npy')\n",
      "#     minutes = np.load('data/notebook_data/minutes.npy')\n",
      "#     cmes = np.load('data/notebook_data/cmes.npy')\n",
      "#     halos = np.load('data/notebook_data/halos.npy')\n",
      "#     time_since = np.load('data/notebook_data/time_since.npy')\n",
      "#     quiet = np.load('data/notebook_data/quiet.npy')\n",
      "# #     sun_discs_rd = np.load('data/notebook_data/sun_discs_rd_1000.npy')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def bin_for_NB(array_in, bins):\n",
      "    array_out = np.zeros(array_in.shape,dtype = np.uint8)\n",
      "    min_X = np.min(array_in)\n",
      "    max_X = np.max(array_in)\n",
      "    bin_width = (max_X - min_X)/(bins)\n",
      "    for b in range(bins):\n",
      "        bin_mask = (array_in >= min_X + bin_width*b) & (array_in < min_X + bin_width*(b+1))\n",
      "        array_out[bin_mask] = b\n",
      "    array_out[array_in == max_X] = b\n",
      "    \n",
      "    return array_out     "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# sun_discs = np.load('data/notebook_data/sun_discs.npy')\n",
      "training_X = sun_discs_rd\n",
      "training_y = cmes\n",
      "print (training_X.shape), (training_y.shape)\n",
      "\n",
      "# Look at any subset?\n",
      "training_X = training_X[:,:]\n",
      "training_y = training_y[:]\n",
      "print (training_X.shape), (training_y.shape)\n",
      "\n",
      "# Bin data for Naiive Bayes?\n",
      "bins = 255\n",
      "training_X = bin_for_NB(training_X,bins)\n",
      "print (training_X.shape), (training_y.shape)\n",
      "\n",
      "# Include time since feature? (1001)\n",
      "# training_X = np.concatenate((training_X, np.reshape(time_since, [time_since.shape[0],1])), axis = 1)\n",
      "\n",
      "# plt.hist(training_X[1001,:])\n",
      "# plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(126144, 100) (126144,)\n",
        "(126144, 100) (126144,)\n",
        "(126144, 100)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (126144,)\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# this_time_since = time_since[:]\n",
      "# training_X = np.concatenate((training_X, np.reshape(this_time_since, [this_time_since.shape[0],1])), axis = 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 218
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 165
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import metrics\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.metrics import classification_report, roc_auc_score \n",
      "# X_split1, X_split2, y_split1, y_split2 = train_test_split(training_X, training_y, test_size=0.50)\n",
      "# del training_X, training_y\n",
      "X_train, X_test, y_train, y_test = train_test_split(training_X, training_y, test_size=0.30)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.naive_bayes import MultinomialNB \n",
      "\n",
      "MNB = MultinomialNB(alpha=1)\n",
      "MNB.fit(X_train ,y_train)\n",
      "y_predict_train = MNB.predict(X_train )\n",
      "y_predict_test = MNB.predict(X_test )\n",
      "print MNB.score(X_train ,y_train)\n",
      "print MNB.score(X_test ,y_test)\n",
      "print metrics.classification_report(y_train, y_predict_train)\n",
      "print metrics.classification_report(y_test, y_predict_test)\n",
      "print roc_auc_score(y_train, y_predict_train)\n",
      "print roc_auc_score(y_test, y_predict_test)\n",
      "# print MNB.feature_log_prob_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.976919592299\n",
        "0.978358524469\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       0.98      1.00      0.99     86317\n",
        "          1       0.02      0.00      0.00      1983\n",
        "\n",
        "avg / total       0.96      0.98      0.97     88300\n",
        "\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       0.98      1.00      0.99     37033\n",
        "          1       0.17      0.00      0.00       811\n",
        "\n",
        "avg / total       0.96      0.98      0.97     37844\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.499927757523\n",
        "0.501098030906\n"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# from sklearn.ensemble import AdaBoostClassifier \n",
      "\n",
      "# MNB = AdaBoostClassifier()\n",
      "# MNB.fit(X_split1,y_split1)\n",
      "# y_predict1 = MNB.predict(X_split1)\n",
      "# y_predict2 = MNB.predict(X_split2)\n",
      "# metrics.classification_report(y_split1, y_predict1)  \n",
      "# print MNB.score(X_split1,y_split1)\n",
      "# print MNB.score(X_split2,y_split2)\n",
      "# print metrics.classification_report(y_split1, y_predict1)\n",
      "# print metrics.classification_report(y_split2, y_predict2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier  \n",
      "RF = RandomForestClassifier(min_samples_split=1000)\n",
      "\n",
      "\n",
      "RF.fit(X_train,y_train)\n",
      "y_predict_train = RF.predict(X_train)\n",
      "y_predict_test = RF.predict(X_test)  \n",
      "print RF.score(X_train,y_train)\n",
      "print RF.score(X_test,y_test)\n",
      "print metrics.classification_report(y_train, y_predict_train)\n",
      "print metrics.classification_report(y_test, y_predict_test)\n",
      "print roc_auc_score(y_train, y_predict_train)\n",
      "print roc_auc_score(y_test, y_predict_test)\n",
      "print RF.feature_importances_\n",
      "# for rank in sorted(importance):\n",
      "#     print rank\n",
      "# plt.scatter(training_X[:,1], training_y)\n",
      "# predict_all = RF.predict(training_X) \n",
      "# plt.hold\n",
      "# plt.scatter(training_X[:,1],predict_all,color='r')\n",
      "# plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.977633069083\n",
        "0.978517070077"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       0.98      1.00      0.99     86317\n",
        "          1       1.00      0.00      0.01      1983\n",
        "\n",
        "avg / total       0.98      0.98      0.97     88300\n",
        "\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       0.98      1.00      0.99     37033\n",
        "          1       0.00      0.00      0.00       811\n",
        "\n",
        "avg / total       0.96      0.98      0.97     37844\n",
        "\n",
        "0.502017145739\n",
        "0.499972997057\n",
        "[ 0.00682839  0.01037219  0.02134813  0.01047862  0.01146577  0.00904527\n",
        "  0.02333466  0.01622451  0.01064175  0.01132251  0.01863388  0.01727363\n",
        "  0.0146781   0.02819567  0.01268655  0.02366023  0.01026029  0.01399814\n",
        "  0.00731712  0.00985423  0.01133595  0.01624107  0.01451446  0.01240261\n",
        "  0.00781377  0.01575121  0.01621863  0.00787582  0.01267462  0.01888393\n",
        "  0.01389626  0.00759693  0.01146524  0.00964384  0.00838153  0.00790948\n",
        "  0.01013946  0.01885344  0.01046705  0.00890625  0.0089038   0.01151281\n",
        "  0.00908275  0.01368547  0.01153704  0.00251405  0.0069276   0.01112436\n",
        "  0.01694798  0.0067868   0.00885203  0.00638157  0.00624673  0.01110972\n",
        "  0.00774937  0.00608681  0.01316196  0.01574055  0.00756936  0.00455253\n",
        "  0.0087294   0.00991707  0.00554568  0.00872069  0.00483358  0.01277832\n",
        "  0.01703054  0.00695606  0.0106839   0.00416665  0.00366901  0.01071228\n",
        "  0.00441888  0.00481859  0.00527456  0.00878114  0.00692792  0.01212825\n",
        "  0.00380138  0.00889898  0.01155157  0.00322141  0.00588177  0.00440924\n",
        "  0.01378771  0.00564946  0.00505262  0.01076028  0.00569991  0.0044518\n",
        "  0.00332541  0.00582077  0.00908925  0.00897341  0.00497759  0.00424529\n",
        "  0.00269938  0.00226533  0.00966102  0.00461939]\n"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import LogisticRegression \n",
      "\n",
      "MNB = LogisticRegression(penalty='l2', C=0.0000006)\n",
      "MNB.fit(X_train ,y_train)\n",
      "y_predict_train = MNB.predict(X_train )\n",
      "y_predict_test = MNB.predict(X_test )\n",
      "print MNB.score(X_train ,y_train)\n",
      "print MNB.score(X_test ,y_test)\n",
      "print metrics.classification_report(y_train, y_predict_train)\n",
      "print metrics.classification_report(y_test, y_predict_test)\n",
      "print roc_auc_score(y_train, y_predict_train)\n",
      "print roc_auc_score(y_test, y_predict_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.958055555556\n",
        "0.95725388601"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       0.96      1.00      0.98      3437\n",
        "          1       1.00      0.07      0.14       163\n",
        "\n",
        "avg / total       0.96      0.96      0.94      3600\n",
        "\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       0.96      1.00      0.98      1479\n",
        "          1       0.00      0.00      0.00        65\n",
        "\n",
        "avg / total       0.92      0.96      0.94      1544\n",
        "\n",
        "0.536809815951\n",
        "0.499661933739\n"
       ]
      }
     ],
     "prompt_number": 208
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import BaggingClassifier  \n",
      "BC = BaggingClassifier( max_samples=75)\n",
      "BC.fit(X_train,y_train)\n",
      "y_predict_train = BC.predict(X_train)\n",
      "y_predict_test = BC.predict(X_test)  \n",
      "print BC.score(X_train,y_train)\n",
      "print BC.score(X_test,y_test)\n",
      "print metrics.classification_report(y_train, y_predict_train)\n",
      "print metrics.classification_report(y_test, y_predict_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.513827862497\n",
        "0.483423749247"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       0.51      0.65      0.57      1923\n",
        "          1       0.52      0.38      0.44      1946\n",
        "\n",
        "avg / total       0.52      0.51      0.50      3869\n",
        "\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       0.48      0.61      0.54       811\n",
        "          1       0.49      0.36      0.42       848\n",
        "\n",
        "avg / total       0.49      0.48      0.48      1659\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "KNN = KNeighborsClassifier(n_neighbors=3)\n",
      "KNN.fit(X_train,y_train)\n",
      "y_predict_train = KNN.predict(X_train)\n",
      "y_predict_test = KNN.predict(X_test)  \n",
      "print KNN.score(X_train,y_train)\n",
      "print KNN.score(X_test,y_test)\n",
      "print metrics.classification_report(y_train, y_predict_train)\n",
      "print metrics.classification_report(y_test, y_predict_test)\n",
      "print roc_auc_score(y_train, y_predict_train)\n",
      "print roc_auc_score(y_test, y_predict_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.600155078832\n",
        "0.312839059675"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       0.61      0.54      0.57      1924\n",
        "          1       0.59      0.66      0.62      1945\n",
        "\n",
        "avg / total       0.60      0.60      0.60      3869\n",
        "\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       0.29      0.29      0.29       810\n",
        "          1       0.33      0.33      0.33       849\n",
        "\n",
        "avg / total       0.31      0.31      0.31      1659\n",
        "\n",
        "0.59981922302\n",
        "0.312317323212\n"
       ]
      }
     ],
     "prompt_number": 150
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# n_components = 16\n",
      "# plot_PCAS(sun_discs, cmes, n_components, 'PCA')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# n_components = 9\n",
      "# plot_PCAS(sun_discs, quiet, n_components)\n",
      "# n_components = 9\n",
      "# plot_PCAS(sun_discs, halos, n_components)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# plt.scatter(months[cmes==1], cmes[cmes==1])\n",
      "# plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# plt.hist(sun_discs[50000,:])\n",
      "# plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# tmp = pca.inverse_transform(RF.feature_importances_)\n",
      "# plt.imshow(masked_to_image(tmp + np.abs(tmp), sun_mask, image_size), cmap='Reds')\n",
      "# plt.title('Feature Importances')\n",
      "# plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# pca.inverse_transform(RF.feature_importances_)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# sun_discs = np.load('data/notebook_data/sun_discs.npy')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 93
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_PCAS(sun_discs[sun_discs.shape[0] -2592: ,:], np.ones(2592 ), 16, 'RPCA')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done in 7.983s\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "4*24*27"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "2592"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
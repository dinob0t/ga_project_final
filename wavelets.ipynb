{
 "metadata": {
  "name": "",
  "signature": "sha256:539713e98d517ca229a52855fe5db52edef3e43a0fe127523082efa440e1c42c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from time import time\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "import os\n",
      "import Image as im\n",
      "import datetime as dt\n",
      "import pywt\n",
      "\n",
      "# Images in file\n",
      "basedir = 'data/all_256/'\n",
      "flist = os.listdir(basedir)\n",
      "flist = sorted(flist)\n",
      "num_images = len(flist)\n",
      "\n",
      "def masked_to_image(masked, sun_mask, image_size):\n",
      "    sun_image = np.zeros([image_size**2])\n",
      "    sun_image[sun_mask==1] = masked\n",
      "    sun_image = sun_image.reshape([image_size, image_size])\n",
      "    return sun_image\n",
      "\n",
      "# Create mask array to select only within solar disk\n",
      "def make_sun_mask(centre, radius, image_size):\n",
      "    sun_mask = np.zeros([image_size,image_size], dtype=np.uint8)\n",
      "    for i in range(image_size):\n",
      "        for j in range(image_size):\n",
      "            dist = np.sqrt((centre[0] - i)**2 + (centre[1] - j)**2)\n",
      "            if dist<= radius:\n",
      "                sun_mask[i,j] = 1\n",
      "    return sun_mask\n",
      "# Make sun mask\n",
      "# Hi-res images\n",
      "# image_size = 512\n",
      "# centre = (255,255)\n",
      "# radius = 472/2\n",
      "\n",
      "\n",
      "# Low-res images\n",
      "image_size = 128\n",
      "centre = (127.5/2,127.5/2)\n",
      "radius = 234/4.0\n",
      "\n",
      "sun_mask_128 = make_sun_mask(centre, radius, image_size)\n",
      "# Flatten array\n",
      "sun_mask_128 = np.ravel(sun_mask_128)\n",
      "\n",
      "\n",
      "# Low-res images\n",
      "image_size = 256\n",
      "centre = (127.5,127.5)\n",
      "radius = 234/2.0\n",
      "\n",
      "sun_mask = make_sun_mask(centre, radius, image_size)\n",
      "# Flatten array\n",
      "sun_mask = np.ravel(sun_mask)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Initialise arrays\n",
      "years = np.zeros(num_images, dtype=np.uint16)\n",
      "months = np.zeros(num_images, dtype=np.uint8)\n",
      "days = np.zeros(num_images, dtype=np.uint8)\n",
      "hours = np.zeros(num_images, dtype=np.uint8)\n",
      "minutes = np.zeros(num_images, dtype=np.uint8)\n",
      "sun_discs_wavelet = np.zeros([num_images,3*10755], dtype=np.int32)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get all vector magnetogram files\n",
      "count = 0\n",
      "for image_file in flist:    \n",
      "    years[count] = image_file[0:4]\n",
      "    months[count] = image_file[4:6]\n",
      "    days[count] = image_file[6:8]\n",
      "    hours[count] = image_file[9:11]\n",
      "    minutes[count] = image_file[11:13]\n",
      "    \n",
      "    cur_file = basedir + image_file  \n",
      "    # Read image, convert to greyscale, convert to np array\n",
      "    cur_image = np.asarray(im.open(cur_file).convert('L'))\n",
      "    \n",
      "    cur_image = np.ravel(cur_image)\n",
      "    cur_image = cur_image[sun_mask == 1]\n",
      "    cur_image = masked_to_image(cur_image, sun_mask, image_size)\n",
      "    coeffs = pywt.wavedec2(cur_image, 'haar', level=1)\n",
      "    cA1, (cH1, cV1, cD1) = coeffs\n",
      "#     cA2, (cH8, cV8, cD8),(cH7, cV7, cD7),(cH6, cV6, cD6),(cH5, cV5, cD5), \\\n",
      "#         (cH4, cV4, cD4),(cH3, cV3, cD3),(cH2, cV2, cD2), (cH1, cV1, cD1) = coeffs\n",
      "    cH1 = cH1.ravel()\n",
      "    cV1 = cV1.ravel()\n",
      "    cD1 = cD1.ravel()\n",
      "    \n",
      "    cH1_min = abs(np.min(cH1))\n",
      "    cV1_min = abs(np.min(cV1))\n",
      "    cD1_min = abs(np.min(cD1))\n",
      "#     cA1 = cA1.ravel()\n",
      "#     sun_discs_wavelet[count,0:10755] = cA1[sun_mask_128 == 1]\n",
      "    sun_discs_wavelet[count,0:10755] = cH1[sun_mask_128 == 1] + cH1_min\n",
      "    sun_discs_wavelet[count,1*10755 :2*10755 ] = cV1[sun_mask_128 == 1] + cV1_min\n",
      "    sun_discs_wavelet[count,2*10755 :3*10755 ] = cD1[sun_mask_128 == 1] + cD1_min\n",
      "    \n",
      "#     np.concatenate((cA2.ravel(),cH8.ravel(),cV8.ravel(), \\\n",
      "#         cD8.ravel(),cH7.ravel(),cV7.ravel(),cD7.ravel(), cH6.ravel(),cV6.ravel(), \\\n",
      "#         cD6.ravel(),cH5.ravel(),cV5.ravel(),cD5.ravel(),cH4.ravel(),cV4.ravel(), \\\n",
      "#         cD4.ravel(),cH3.ravel(),cV3.ravel(),cD3.ravel(),cH2.ravel(),cV2.ravel(), \\\n",
      "#         cD2.ravel(),cH1.ravel(),cV1.ravel(),cD1.ravel()))\n",
      "    \n",
      "    if count%10000 == 0 and count > 0:\n",
      "        print str(count) + ' of ' + str(num_images) +' , File: '+ image_file \n",
      "    count +=1 \n",
      "print 'Done'\n",
      "# np.save('data/notebook_data/sun_discs_wavelet',sun_discs_wavelet)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10000 of 126144 , File: 20100814_054500_M_256.jpg\n",
        "20000 of 126144 , File: 20101129_230000_M_256.jpg"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "30000 of 126144 , File: 20110316_220000_M_256.jpg"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "40000 of 126144 , File: 20110701_074500_M_256.jpg"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "50000 of 126144 , File: 20111016_021500_M_256.jpg"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "60000 of 126144 , File: 20120129_120000_M_256.jpg"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "70000 of 126144 , File: 20120515_144500_M_256.jpg"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "80000 of 126144 , File: 20120828_071500_M_256.jpg"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "90000 of 126144 , File: 20121213_001500_M_256.jpg"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "100000 of 126144 , File: 20130329_181500_M_256.jpg"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "110000 of 126144 , File: 20130713_053000_M_256.jpg"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "120000 of 126144 , File: 20131028_180000_M_256.jpg"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Done"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#####################################################################################\n",
      "# Import lasco CME catalogue - \n",
      "# Date\n",
      "# Time\n",
      "# Central_PA : Central size [deg] \n",
      "# Width : Angular width [deg]\n",
      "# L_speed : linear speed\n",
      "# 2nd_o_speed : 2nd order speed fit\n",
      "# 2nd_o_speed_20R : 2nd order speed fit @ 20R\n",
      "# Accel : Acceleration\n",
      "# Mass :\n",
      "# KE : Kinetic energy\n",
      "# MPA : Measurement position angle\n",
      "df_cmes = pd.read_csv(\"cme_catalogue.md\",delim_whitespace=True,error_bad_lines =False, warn_bad_lines=False )\n",
      "df_cmes.drop(['Comment1','Comment2', 'Comment3'], axis=1, inplace=True)\n",
      "df_cmes[['year','month','day']] = df_cmes.Date.str.extract('(\\d\\d\\d\\d)/(\\d\\d)/(\\d\\d)')\n",
      "df_cmes[['hour','minute']] = df_cmes.Time.str.extract('(\\d\\d):(\\d\\d)')\n",
      "\n",
      "df_cmes.drop(['Date','Time','KE','Mass','MPA'],axis=1, inplace=True)    \n",
      "df_cmes['CME'] = 1\n",
      "df_cmes['halo'] = df_cmes.Central_PA\n",
      "df_cmes.ix[df_cmes.halo!='Halo', 'halo'] = 0\n",
      "df_cmes.ix[df_cmes.halo=='Halo', 'halo'] = 1\n",
      "df_cmes.ix[df_cmes.Central_PA=='Halo', 'Central_PA'] = 360\n",
      "# Make the features integer\n",
      "for feature in df_cmes.columns:\n",
      "    df_cmes[feature] = df_cmes[feature].astype(int)\n",
      "# Sort all on year -> month->day\n",
      "df_cmes = df_cmes.sort(columns=['year','month','day'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Make datetime object in a new columns\n",
      "df_cmes['datetime'] = df_cmes.year\n",
      "for index in range(len(df_cmes)):\n",
      "    df_cmes.ix[index,'datetime'] = dt.datetime(df_cmes.ix[index,'year'],\n",
      "                                               df_cmes.ix[index,'month'],\n",
      "                                               df_cmes.ix[index,'day'],\n",
      "                                               df_cmes.ix[index,'hour'],\n",
      "                                               df_cmes.ix[index,'minute'])\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Clip to existing vector magnetogram data\n",
      "df_cmes = df_cmes[(df_cmes.year >= years[0]) & (df_cmes.month >= months[0])]\n",
      "df_cmes = df_cmes[(df_cmes.year <= years[-1]) & (df_cmes.month <= months[-1])]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Empty arrays to list indexes of events\n",
      "cmes = np.zeros(num_images, dtype=np.uint8)\n",
      "halos = np.zeros(num_images, dtype=np.uint8)\n",
      "start = 1\n",
      "for index2 in range(0,len(df_cmes)): \n",
      "    cur_row = df_cmes.iloc[index2]\n",
      "    for index in range(start, num_images):        \n",
      "        cur_datetime = dt.datetime(years[index],\n",
      "                                   months[index],\n",
      "                                   days[index],\n",
      "                                   hours[index],\n",
      "                                   minutes[index])\n",
      "       \n",
      "        if cur_datetime > cur_row.datetime:\n",
      "            break\n",
      "    cmes[index-1] = 1\n",
      "    if cur_row.halo == 1:\n",
      "        halos[index-1] = 1 \n",
      "        start = index-1\n",
      "        \n",
      "    if index2%100 == 0 and index2 > 0:\n",
      "        print str(index2) + ' of ' + str(len(df_cmes)) + ' CMEs processed'\n",
      "print 'Done'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "100 of 2852 CMEs processed\n",
        "200 of 2852 CMEs processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "300 of 2852 CMEs processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "400 of 2852 CMEs processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "500 of 2852 CMEs processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "600 of 2852 CMEs processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "700 of 2852 CMEs processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "800 of 2852 CMEs processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "900 of 2852 CMEs processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1000 of 2852 CMEs processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1100 of 2852 CMEs processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1200 of 2852 CMEs processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1300 of 2852 CMEs processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1400 of 2852 CMEs processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1500 of 2852 CMEs processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1600 of 2852 CMEs processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1700 of 2852 CMEs processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1800 of 2852 CMEs processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1900 of 2852 CMEs processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2000 of 2852 CMEs processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2100 of 2852 CMEs processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2200 of 2852 CMEs processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2300 of 2852 CMEs processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2400 of 2852 CMEs processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2500 of 2852 CMEs processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2600 of 2852 CMEs processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2700 of 2852 CMEs processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2800 of 2852 CMEs processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Done"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create a column of time since the last CME\n",
      "# Note that it's not inclusive, i.e. even if a CME happened\n",
      "# on that datetime we still calculate the time since the next last\n",
      "# CME so that we can use it as a predictor\n",
      "time_since = np.zeros(num_images, dtype=np.uint8)\n",
      "time_since[0] = 1\n",
      "for index in range(1,num_images):\n",
      "    if cmes[index-1] == 1 or index == 1:\n",
      "        start_datetime = dt.datetime(years[index-1],\n",
      "                                   months[index-1],\n",
      "                                   days[index-1],\n",
      "                                   hours[index-1],\n",
      "                                   minutes[index-1]) \n",
      "    cur_datetime = dt.datetime(years[index],\n",
      "                               months[index],\n",
      "                               days[index],\n",
      "                               hours[index],\n",
      "                               minutes[index]) \n",
      "    time_since[index] = (cur_datetime - start_datetime).seconds/(60*15)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "quiet = np.zeros(num_images, dtype=np.uint8)\n",
      "indexes = np.where(cmes)[0]\n",
      "for index in range(0,len(indexes)-1):\n",
      "    start = indexes[index]\n",
      "    stop = indexes[index+1]\n",
      "    if (stop-start)/2 != 0:\n",
      "        quiet[indexes[index]+ (stop-start)/2] = 1\n",
      "        \n",
      "# quiet_tmp = np.ones(num_images, dtype=np.uint8)\n",
      "# quiet_tmp = quiet_tmp - cmes\n",
      "# random_list = sorted(random.sample(xrange(len(quiet_tmp)), 4000))\n",
      "# quiet = np.zeros(num_images, dtype=np.uint8)\n",
      "# quiet[random_list] = quiet_tmp[random_list]\n",
      "\n",
      "both = quiet + cmes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Number of pre-CME frames: ' + str(np.sum(cmes))\n",
      "print 'Total number of CMEs: ' + str(sum(df_cmes.CME==1))\n",
      "print 'Number of pre-halo frames: ' + str(np.sum(halos))\n",
      "print 'Total number of halos: ' + str(sum(df_cmes.halo==1))\n",
      "print 'Number of quiet frames: ' + str(np.sum(quiet))\n",
      "print 'Number of cme + quiet frames: ' + str(np.sum(both))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of pre-CME frames: 2794\n",
        "Total number of CMEs: 2852\n",
        "Number of pre-halo frames: 134\n",
        "Total number of halos: 134\n",
        "Number of quiet frames: 2734\n",
        "Number of cme + quiet frames: 5528\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Set up training / target data\n",
      "training_X = sun_discs_wavelet\n",
      "training_y = cmes\n",
      "print (training_X.shape), (training_y.shape)\n",
      "# training_X = np.concatenate((training_X, np.reshape(time_since, [time_since.shape[0],1])), axis = 1)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(126144, 32265) (126144,)\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import metrics\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.metrics import classification_report, roc_auc_score \n",
      "# X_split1, X_split2, y_split1, y_split2 = train_test_split(training_X, training_y, test_size=0.50)\n",
      "# del training_X, training_y\n",
      "X_train, X_test, y_train, y_test = train_test_split(training_X, training_y, test_size=0.30)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.naive_bayes import MultinomialNB \n",
      "\n",
      "MNB = MultinomialNB()\n",
      "MNB.fit(X_train ,y_train)\n",
      "y_predict_train = MNB.predict(X_train )\n",
      "y_predict_test = MNB.predict(X_test )\n",
      "print 'R^2 train: ' + str(MNB.score(X_train ,y_train))\n",
      "print 'R^2 test: ' + str(MNB.score(X_test ,y_test))\n",
      "print metrics.classification_report(y_train, y_predict_train)\n",
      "print metrics.classification_report(y_test, y_predict_test)\n",
      "auc1= roc_auc_score(y_train, y_predict_train)\n",
      "auc2= roc_auc_score(y_test, y_predict_test)\n",
      "print 'Area Under Curve train: ' + str(auc1)\n",
      "print 'Area Under Curve test: ' + str(auc2)\n",
      "print 'Area Under Curve average: ' + str((auc1+auc2)/2)\n",
      "# print MNB.feature_log_prob_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}